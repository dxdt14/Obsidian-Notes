{
  "main": {
    "id": "19ac1ab3a284b403",
    "type": "split",
    "children": [
      {
        "id": "eba51ddbf6c97996",
        "type": "tabs",
        "children": [
          {
            "id": "bc7119acec801487",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM Distillation/Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models"
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "a678408e9d1ce721",
    "type": "split",
    "children": [
      {
        "id": "0a1386a491eab93b",
        "type": "tabs",
        "children": [
          {
            "id": "1cc4516d1c782c33",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "12c4a84d751fba2f",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "849c41852ae91181",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "right": {
    "id": "df000523228b73b0",
    "type": "split",
    "children": [
      {
        "id": "80df5d10b0303c54",
        "type": "tabs",
        "children": [
          {
            "id": "fbf56d3fc21fd3a4",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "LLM Distillation/Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "Backlinks for Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models"
            }
          },
          {
            "id": "371a37253457d229",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "LLM Distillation/Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "Outgoing links from Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models"
            }
          },
          {
            "id": "86869556665d4e21",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "12358fb65a8c22a0",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "LLM Distillation/Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models.md"
              },
              "icon": "lucide-list",
              "title": "Outline of Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models"
            }
          },
          {
            "id": "498ff9f8e6a4a1fc",
            "type": "leaf",
            "state": {
              "type": "git-view",
              "state": {},
              "icon": "git-pull-request",
              "title": "Source Control"
            }
          }
        ],
        "currentTab": 4
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false,
      "obsidian-git:Open Git source control": false
    }
  },
  "active": "bc7119acec801487",
  "lastOpenFiles": [
    "LLM Distillation/Screen Shot 2024-10-23 at 5.00.17 PM.png",
    "LLM Distillation/Screen Shot 2024-10-23 at 4.52.01 PM.png",
    "LLM Distillation/Distilling the Knowledge in a Neural Network.md",
    "LLM Distillation/Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models.md",
    "Quantum NFL Notes/Quantum Graphs/Community Detection in Quantum Complex Networks.md",
    "Quantum NFL Notes/Quantum Graphs/Original Quantum Experiments -> Graph Theory paper.md",
    "Quantum NFL Notes/Quantum Graphs/Quantum Experiments->Graph Theory.md",
    "Quantum NFL Notes/Community Detection Notes.md",
    "Analogical Reasoning/Emergent Analogical Reasoning in LLMs.md",
    "Quantum NFL Notes/Quantum Graphs/Quantum Random Networks.md",
    "Analogical Reasoning",
    "LLM Distillation",
    "Quantum NFL Notes/Quantum Graphs/Symmetries in Quantum Networks.md",
    "Quantum NFL Notes/Quantum Graphs/Quantum Graphs.md"
  ]
}